#!/usr/bin/env python
import sys, os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import datetime
import json
from subprocess import call
import urllib

import numpy as np

from opensfm import dataset
from opensfm import reconstruction
from opensfm import transformations as tf
from opensfm import types


def run_dataset(run_root, name):
    folder = run_root + '/' + name
    call(['bin/opensfm_run_all', folder])

    with open(run_root + '/index.html', 'a') as fout:
        s = '''
<a href="/viewer/reconstruction.html#file=../{0}/reconstruction.json">{1}</a><br>
'''.format(urllib.quote(folder), name)
        fout.write(s)


def align_reconstructions(rgt, r):
    if len(r.shots) < 3:
        return
    # Compute similarity Xp = s A X + b
    X, Xp = [], []
    for key in rgt.shots:
        if key in r.shots:
            X.append(r.shots[key].pose.get_origin())
            Xp.append(rgt.shots[key].pose.get_origin())
        else:
            print 'Shot {0} missing.'.format(key)
    X = np.array(X)
    Xp = np.array(Xp)
    T = tf.superimposition_matrix(X.T, Xp.T, scale=True)

    A, b = T[:3, :3], T[:3, 3]
    s = np.linalg.det(A)**(1. / 3)
    A /= s
    reconstruction.apply_similarity(r, s, A, b)


def optical_center_rms(rgt, r):
    X = []
    Xp = []
    for key in rgt.shots:
        if key in r.shots:
            X.append(r.shots[key].pose.get_origin())
            Xp.append(rgt.shots[key].pose.get_origin())
    X = np.array(X)
    Xp = np.array(Xp)
    return np.sqrt(((X - Xp)**2).sum() / len(X))


def focal_length_rms(rgt, r):
    f = []
    fp = []
    for key in r.shots:
        f.append(r.shots[key].camera.focal)
        fp.append(rgt.shots[key].camera.focal)
    f = np.array(f)
    fp = np.array(fp)
    return np.sqrt(((f - fp)**2).sum() / len(f))


def eval_reconstruction(name, rgt, r):
    align_reconstructions(rgt, r)
    f = focal_length_rms(rgt, r)
    o = optical_center_rms(rgt, r)
    print '#####################################################################'
    print '# Evaluation for', name
    print '#   Focal lenght RMS error:', f
    print '#   Optical center RMS error:', o
    print '#####################################################################'
    return {
        "focal_length_rms": f,
        "optical_center_rms": o,
    }


def load_strecha_camera(filename):
    words = open(filename).read().split()
    K = np.array(map(float, words[:9])).reshape(3, 3)
    R = np.array(map(float, words[12:21])).reshape(3, 3)
    t = np.array(map(float, words[21:24]))
    width, height = map(int, words[24:26])
    return K, R, t, width, height


def load_strecha_gt_projections(run_root, name):
    source = 'eval/datasets/{0}/urd'.format(name)
    r = types.Reconstruction()
    images = [i for i in os.listdir(source) if i.endswith('.png')]

    filename = source + '/' + images[0] + '.camera'
    K, R, t, width, height = load_strecha_camera(filename)
    camera = types.PerspectiveCamera()
    camera.id = 'canon eos d60'
    camera.width = width
    camera.height = height
    camera.focal = K[0, 0] / width
    camera.focal_prior = camera.focal
    r.add_camera(camera)

    for i in images:
        filename = source + '/' + i + '.camera'
        K, R, t, width, height = load_strecha_camera(filename)
        shot = types.Shot()
        shot.id = i
        shot.camera = camera
        shot.pose = types.Pose()
        shot.pose.set_rotation_matrix(R)
        shot.pose.translation = t
        r.add_shot(shot)
    return r


def eval_strecha_dataset(run_root, name):
    folder = run_root + '/' + name
    source = '../../../datasets/{0}/urd'.format(name)
    call(['mkdir', '-p', folder])
    call(['ln', '-s', source, folder + '/images'])
    with open(folder + '/camera_models_overrides.json', 'w') as fout:
        d = {
            "all": {
                "projection_type": "perspective",
                "width": 3072,
                "height": 2048,
                "focal": 0.881057268722467,
            }
        }
        json.dump(d, fout, indent=4)

    run_dataset(run_root, name)

    data = dataset.DataSet(folder)
    r = data.load_reconstruction()[0]
    rgt = load_strecha_gt_projections(run_root, name)
    return eval_reconstruction(name, rgt, r)


if __name__ == '__main__':
    if len(sys.argv) == 2:
        run_root = sys.argv[1]
    else:
        run_root = 'eval/runs/' + datetime.datetime.now().isoformat()

    # Create evaluation folders
    call(['mkdir', '-p', run_root])

    # Strecha datasets
    results = {}
    for name in ['fountain_dense',
                 'herzjesu_dense',
                 'castle_entry_dense',
                 'castle_dense',
                 'herzjesu_dense_large',
                 'castle_dense_large',
                 ]:
        results[name] = eval_strecha_dataset(run_root, name)

    with open(run_root + '/results.json', 'w') as fout:
        json.dump(results, fout, indent=4)
